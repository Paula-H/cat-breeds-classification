{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Importing all the necessary libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "528dce7ae9d8d6a3"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import cv2 as cv2\n",
    "import numpy as np\n",
    "from keras import datasets,layers,models, preprocessing\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T21:03:31.859288700Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generating training and validating image sets from a bigger archive"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b33e280b75b69b3"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-03T21:03:51.400524100Z"
    }
   },
   "id": "3b39e48b57abfee9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The class names the cats can be identified into"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f2003b2b4398642"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class_names = [\"bengal\",\"domestic_shorthair\",\"maine_coon\",\"ragdoll\",\"siamese\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T21:03:58.804392400Z",
     "start_time": "2024-03-03T21:03:58.795443500Z"
    }
   },
   "id": "d6214505a26d3e18"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 951 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "training_data = train_datagen.flow_from_directory(\n",
    "    \"cat_v1\",\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T21:04:31.830400200Z",
     "start_time": "2024-03-03T21:04:31.770583900Z"
    }
   },
   "id": "154680691c9890dd"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 951 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "validating_data = valid_datagen.flow_from_directory(\n",
    "    \"cat_v1\",\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T21:04:45.834862400Z",
     "start_time": "2024-03-03T21:04:45.772846500Z"
    }
   },
   "id": "e40cabc79cc06902"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating a new model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc2f55ade937e56e"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(32,32,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(5,activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T21:06:12.276540Z",
     "start_time": "2024-03-03T21:06:12.221685400Z"
    }
   },
   "id": "c3b71900f33500ed"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Notes\\Statistica\\Laborator 5\\CatBreedsClassification\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m30/30\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m51s\u001B[0m 1s/step - accuracy: 0.2516 - loss: 1.6062 - val_accuracy: 0.3554 - val_loss: 1.5092\n",
      "Epoch 2/10\n",
      "\u001B[1m30/30\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m48s\u001B[0m 1s/step - accuracy: 0.3253 - loss: 1.4762 - val_accuracy: 0.4122 - val_loss: 1.3814\n",
      "Epoch 3/10\n",
      "\u001B[1m30/30\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m48s\u001B[0m 1s/step - accuracy: 0.4217 - loss: 1.3473 - val_accuracy: 0.4069 - val_loss: 1.3388\n",
      "Epoch 4/10\n",
      "\u001B[1m30/30\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m48s\u001B[0m 1s/step - accuracy: 0.4221 - loss: 1.3339 - val_accuracy: 0.4522 - val_loss: 1.3132\n",
      "Epoch 5/10\n",
      "\u001B[1m30/30\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m48s\u001B[0m 1s/step - accuracy: 0.4563 - loss: 1.3189 - val_accuracy: 0.4458 - val_loss: 1.2805\n",
      "Epoch 6/10\n",
      "\u001B[1m30/30\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m48s\u001B[0m 1s/step - accuracy: 0.4582 - loss: 1.2310 - val_accuracy: 0.4995 - val_loss: 1.2091\n",
      "Epoch 7/10\n",
      "\u001B[1m30/30\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m48s\u001B[0m 1s/step - accuracy: 0.5385 - loss: 1.1896 - val_accuracy: 0.5016 - val_loss: 1.2096\n",
      "Epoch 8/10\n",
      "\u001B[1m30/30\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m48s\u001B[0m 1s/step - accuracy: 0.5312 - loss: 1.1527 - val_accuracy: 0.4921 - val_loss: 1.2443\n",
      "Epoch 9/10\n",
      "\u001B[1m30/30\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m48s\u001B[0m 1s/step - accuracy: 0.4995 - loss: 1.1867 - val_accuracy: 0.5563 - val_loss: 1.0906\n",
      "Epoch 10/10\n",
      "\u001B[1m30/30\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m56s\u001B[0m 2s/step - accuracy: 0.5623 - loss: 1.0837 - val_accuracy: 0.5657 - val_loss: 1.0659\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.history.History at 0x18737edb530>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_data,epochs=10,validation_data=validating_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T21:14:46.629070700Z",
     "start_time": "2024-03-03T21:06:35.757898700Z"
    }
   },
   "id": "1e579ac842ea181c"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "model.save(\"cat_classifier.keras\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T21:17:02.501468400Z",
     "start_time": "2024-03-03T21:17:02.480547300Z"
    }
   },
   "id": "6863e9c095971201"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m30/30\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 818ms/step - accuracy: 0.5891 - loss: 1.0313\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(validating_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T21:16:37.927988600Z",
     "start_time": "2024-03-03T21:16:12.240899700Z"
    }
   },
   "id": "fdee001110943d07"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0644176006317139"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T21:16:52.302285600Z",
     "start_time": "2024-03-03T21:16:52.291651300Z"
    }
   },
   "id": "46459654484ba27"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5657203197479248"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T21:16:57.343355100Z",
     "start_time": "2024-03-03T21:16:57.334405600Z"
    }
   },
   "id": "934af686f6b15004"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "image = cv2.imread(\"kitty2.jpg\")\n",
    "image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T21:22:54.335716900Z",
     "start_time": "2024-03-03T21:22:54.313910300Z"
    }
   },
   "id": "492033b755c479da"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "'ragdoll'"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(np.array([image]) / 255)\n",
    "index = np.argmax(prediction)\n",
    "class_names[index]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T21:22:55.569200800Z",
     "start_time": "2024-03-03T21:22:55.511615100Z"
    }
   },
   "id": "e16143866ddb4d07"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
